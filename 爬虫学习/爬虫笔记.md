
# 爬虫笔记

## 基础知识

1. 概念：模拟客户端（主要指浏览器）发送网络请求，接受请求响应，并按照一定规则自动抓取信息的程序

2. 作用：
   1. 数据采集
   2. 软件测试
   3. 抢票，投票
   4. 网络安全
   
3. 分类：
   1. 数量 ：通用；聚焦爬虫
   2. 是否以获取数据为目的：功能性；数据增量爬虫：url不变数据改变；url改变数据改变。

4. 流程：![爬虫流程](E:\\爬虫流程.png)

5. http
   1. http协议：超文本传输协议，默认端口80
   2. https：http+SSL（安全套接字层，对传输内容进行加密）默认端口；443.

6. 请求头：
   1. Content-Type
   2. 2.host 域名
   3. 3.Connection 长连接
   4. 4.Upgr-Insecure-Requs 升级为https请求
   5. User-Agent 用户代理，提供系统信息和浏览器信息
   6. 6.Referer 页面跳转处
   7. 7.Cookie 本地数据（状态保持）

7. 响应头(常用)：Set-Cookie 对方服务器设置cookie到本地浏览器的缓存

8. 常见响应状态码（对爬虫来说都不可信）：
   + 200成功
   + 302跳转
   + 303浏览器对于POST请求的响应重新定向值新的url
   + 307浏览器对于GET请求的响应重新定向值新的url
   + 403资源不可用；服务器理解用户的请求但拒绝处理（无权限）
   + 404 找不到页面 500服务器内部错误
   + 503服务器由于维护或者负载过重无法应答，在响应中可能携带Retry-After响应头；或者爬虫频繁访问urlnetwork中抓包得到的源码为判断依据，而elements中的源码为渲染之后的，不能作为判断依据。

9. 浏览器运行过程:
   浏览器发送所有请求，并渲染。爬虫一次请求一次回应，不进行渲染。
   抓包：骨骼文件：html静态文件；肌肉文件：js/ajax请求；皮肤文件：css/font(字体)/图片。
   抓包过程：对抓取的包进行分析，获取所需信息。
requests模块：作用：发送请求，获取响应数据。
                        https://requests.readthedocs.io/en/master/user/quickstart/
response.get发送get请求。可添加请求头字典修改默认请求头。
response.text打印str类型源码，可使用response.encoding手动设定编码类型。
response.content是bytes类型的相响应源码。可以response.content.decode()操作解决中文乱码。

response响应对象的其他常用属性或方法
  response.url 响应的url
  response.status_code 响应状态码
  response.request.headers 响应对应的请求头
  response.headers 响应头
  response.requests._cookies 响应对象请求的cookie；返回cookieJar类型
  response.cookies 响应的cookie（set-cookie后的），返回cookieJar类型
  response.json() 自动将json字符串类型的响应内容转换为python对象（dict/list）

url中'?'后面时参数 可逐个（多个）删除确定关键参数

发送带参数的请求
1.直接在url中携带
2.通过params携带参数字典

发送带cookie的请求(需登录的网页需要使用的重要参数,cookie过期需重新获取)
1.直接在headers中带参数(即在headers字典中增加cookie键值对)
2.通过cookies参数携带cookies字典
  键值对：' cookie的name' : 'cookie的value'
    cookie字符串    temp = {}
   稳妥：cookie_list = temp.split('; ')
             cookies = {}
             for cookie in cookie_list:
                 cookies[cookie.split('=')[0]] = cookies[cookie.split('=')[-1]]
   字典推导式：ccokies = {cookie.split('=')[0]: cookie.split('=')[-1] for cookie in temp.split('; ')}
3.cookieJar对象转换为cookie字典
  方法：cookies_dict = requests.utils.dict_from_cookiejar(response.cookies)
      response.cookies为返回的cookieJar类型
      requests.utils.dict_from_cookiejar函数 返回字典类型
      转回方法：cookie_jar = requests.utils.cookiejar_from_dict(cookie_dict)

超时参数timeout的使用
    使用方法：response = requests.get(url, timeout=n) n秒后强制返回结果

代理的使用过程
  理解：网上的一个IP，指向代理服务器
  分类：正向代理（明确请求服务器的IP） 反向代理（不知IP，如 nginx）
  代理IP的分类：
    匿名度：
      1.透明代理
      2.匿名代理
      3.高匿代理（效果最好,无法识别是否为代理，也无法识别个人ip）
    协议：
      1.http
      2.https
      3.socks

proxies(dict)代理参数的使用：
  response = requests.get(url, proxies=proxies)
  proxies = {
    "http(s)": " http(s)://地址串:端口号",
  }
  使用失败时：1.卡滞 2.报错

使用verify参数忽略CA证书
  verify=False （会警告，不影响）

requests发送post请求（登录注册，发送大量文本时一般发送post请求）
  方法：response = requests.post(url, data)
      data 参数应接受dict
      json库中的json.loads()将json字符串转化为字典

































